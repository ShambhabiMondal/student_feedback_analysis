{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLxq4gu-maE-",
        "outputId": "ca2c694f-215d-472a-8196-286df9e6e48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/teacher_review_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8hDkplxmb8R",
        "outputId": "e8f49e40-e37b-4c16-8047-ef3e539498f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/teacher_review_dataset.zip\n",
            "replace teacher_review_dataset.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "Z-S7LtgwmfMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_valid_input(prompt):\n",
        "    while True:\n",
        "        try:\n",
        "            value = int(input(prompt))\n",
        "        except ValueError:\n",
        "            print(\"Sorry, I didn't understand that.\")\n",
        "            continue\n",
        "\n",
        "        if value < 0:\n",
        "            print(\"Sorry, your response must not be negative.\")\n",
        "            continue\n",
        "        elif value == 0:\n",
        "            print(\"Sorry, your response must not be zero.\")\n",
        "            continue\n",
        "        elif value > 5:\n",
        "            print(\"Sorry, your response must not be greater than 5.\")\n",
        "            continue\n",
        "        else:\n",
        "            break\n",
        "    return value"
      ],
      "metadata": {
        "id": "x5cCdYkxmk8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the dataset and drop irrelevant columns\n",
        "df = pd.read_csv(\"teacher_review_dataset.csv\")\n",
        "df1 = df.drop(df.columns[[0, 1, 2]], axis=1)"
      ],
      "metadata": {
        "id": "SKZSPJFbmqDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "scaler = StandardScaler(with_mean=False)\n",
        "X = scaler.fit_transform(df1.iloc[:, :-1])\n",
        "y = df.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "UhgEls_E-6B2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "TvruHkYQmrd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the SVM classifier\n",
        "clf = SVC(kernel='linear', C=100)"
      ],
      "metadata": {
        "id": "k4xKdGinnMEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the classifier\n",
        "history = clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksMoKh8mnQ6P",
        "outputId": "ac2c27c5-4725-47de-bd4a-1d5336262d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=2).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the labels for the test set\n",
        "y_pred = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "VrFmrRVonWI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "loss = log_loss(y_test, y_pred)"
      ],
      "metadata": {
        "id": "pEA9kSXKnXbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Loss:\", loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLpQ8NBVnaIF",
        "outputId": "0cdb48be-fa38-4824-dc22-93e00397ae85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9888888888888889\n",
            "Loss: 0.40048503765685745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the ratings for the questions from the user\n",
        "l1 = []\n",
        "l2 = []\n",
        "print(\"Enter the rating scores for the f4aculty based on the following qustions, on a scale of 1 to 5\")\n",
        "print(\"Poor: 1 Fair: 2 Good: 3, Very Good: 4, Excellent: 5\")\n",
        "q1 = l1.append(get_valid_input(\"The faculty explained the objective of the course. Its relevance in regard to Industrial application, current development and research opportunities.   \"))\n",
        "q2 = l1.append(get_valid_input(\"The prerequisites, pertinence of the course with others and programme as a whole and the organization of the subject matter are explained.   \"))\n",
        "q3 = l1.append(get_valid_input(\"The teacher explained CO statements and its correlations with the PO's and PSO's.   \"))\n",
        "q4 = l1.append(get_valid_input(\"The teacher is enthusiastic and created interest in the subject.   \"))\n",
        "q5 = l1.append(get_valid_input(\"The teacher delivered the lecture lucidly.   \"))\n",
        "q6 = l1.append(get_valid_input(\"The teacher emphasized on numerical problem solving / mathematical formulation etc, example and data analysis.   \"))\n",
        "q7 = l1.append(get_valid_input(\"Teacher used modern and smart teaching aids, whenever relevant.   \"))\n",
        "q8 = l1.append(get_valid_input(\"Test, Assignment and quizzes were adequate.   \"))\n",
        "q9 = l1.append(get_valid_input(\"The teacher provides opportunities for participatory learning.   \"))\n",
        "q10 = l1.append(get_valid_input(\"Your level of satisfaction with the all round contribution of the teacher.   \"))\n",
        "l2.append(l1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAzxj6PFncrg",
        "outputId": "2d6543c5-8ebf-452f-9353-4bf14d86bf5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the rating scores for the f4aculty based on the following qustions, on a scale of 1 to 5\n",
            "Poor: 1 Fair: 2 Good: 3, Very Good: 4, Excellent: 5\n",
            "The faculty explained the objective of the course. Its relevance in regard to Industrial application, current development and research opportunities.   3\n",
            "The prerequisites, pertinence of the course with others and programme as a whole and the organization of the subject matter are explained.   2\n",
            "The teacher explained CO statements and its correlations with the PO's and PSO's.   4\n",
            "The teacher is enthusiastic and created interest in the subject.   3\n",
            "The teacher delivered the lecture lucidly.   3\n",
            "The teacher emphasized on numerical problem solving / mathematical formulation etc, example and data analysis.   4\n",
            "Teacher used modern and smart teaching aids, whenever relevant.   3\n",
            "Test, Assignment and quizzes were adequate.   4\n",
            "The teacher provides opportunities for participatory learning.   2\n",
            "Your level of satisfaction with the all round contribution of the teacher.   3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical data\n",
        "dat_f = pd.DataFrame(l2, columns=['q1', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9', 'q10'])"
      ],
      "metadata": {
        "id": "jn5rIpbEnmaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "X1 = scaler.fit_transform(dat_f)"
      ],
      "metadata": {
        "id": "G6jmNCnM_NsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the label\n",
        "y_pred1 = clf.predict(X1)"
      ],
      "metadata": {
        "id": "gD9lRQh9nnZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the predicted label\n",
        "print(\"The predicted label is:\", y_pred1[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkoQFLEpnqhF",
        "outputId": "72c010bd-0d8f-4d53-ca1d-f04bea3e7f7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The predicted label is: 1\n"
          ]
        }
      ]
    }
  ]
}